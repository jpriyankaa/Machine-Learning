# ğŸ“Š End-to-End Machine Learning Projects

This repository contains a comprehensive collection of end-to-end machine learning projects covering the core algorithms of **Supervised**, **Unsupervised**, and **Ensemble Learning**. Each project includes:

* âœ… Clean, well-commented Python code
* âœ… Step-by-step implementation
* âœ… Simulated real-world datasets
* âœ… Preprocessing, Feature Engineering, Model Training, Evaluation, and Tuning
* âœ… Model comparison and final insights

---

## 1ï¸âƒ£ **Supervised Learning**

### ğŸ”¢ Regression (Predicting numeric values)

* **Linear Regression** â€“ Predict house prices
* **Polynomial Regression** â€“ Car price prediction
* **Decision Tree Regression** â€“ Predict car engine efficiency

### ğŸ· Classification (Predicting categories)

* **Logistic Regression** â€“ Customer churn prediction
* **K-Nearest Neighbors (KNN)** â€“ Predict diabetes risk
* **Decision Tree Classifier** â€“ Predict loan approval
* **Random Forest** â€“ Employee attrition detection
* **Support Vector Machine (SVM)** â€“ Email spam detection
* **Naive Bayes** â€“ News article classification

---

## 2ï¸âƒ£ **Unsupervised Learning**

### ğŸ” Clustering (Group similar items)

* **K-Means Clustering** â€“ Customer segmentation
* **Hierarchical Clustering** â€“ College applicant grouping
* **DBSCAN** â€“ Detecting noise/outliers in spatial data

### ğŸ”„ Dimensionality Reduction (Simplify features)

* **PCA (Principal Component Analysis)** â€“ Compress image data
* **t-SNE** â€“ Visualize high-dimensional user behavior
* **LDA (Linear Discriminant Analysis)** â€“ Class separation on text data

---

## 3ï¸âƒ£ **Ensemble Learning**

### ğŸ§± Bagging

* **Random Forest** â€“ Improve churn prediction accuracy

### ğŸ”¥ Boosting

* **AdaBoost** â€“ Simple classification with weak learners
* **Gradient Boosting** â€“ Predict student performance
* **XGBoost** â€“ Click-through prediction
* **LightGBM** â€“ Insurance policy prediction
* **CatBoost** â€“ Telecom plan upgrade prediction

### ğŸ§  Stacking

* Combine **Random Forest**, **KNN**, and **Logistic Regression** with **SVM** as a meta-model for better prediction (Student pass/fail prediction)

---

## ğŸ“ Structure

Each project includes:

* ğŸ“Œ Problem Statement
* ğŸ“Š Data Understanding
* ğŸ§¼ Data Cleaning & Preprocessing
* ğŸ” Feature Engineering
* ğŸ¤– Model Training
* ğŸ“ˆ Evaluation Metrics (Accuracy, Precision, Recall, F1, Confusion Matrix)
* ğŸ”§ Hyperparameter Tuning
* âœ… Final Model Summary & Suggestions


<img width="529" height="609" alt="image" src="https://github.com/user-attachments/assets/0c7f7c75-1ddd-4dc3-9c32-a679fda5c92c" />

<img width="546" height="302" alt="image" src="https://github.com/user-attachments/assets/954123a4-8525-4809-aa8f-ba3efd2c1e73" />


